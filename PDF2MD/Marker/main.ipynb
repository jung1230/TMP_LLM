{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/VikParuchuri/marker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn single PDF to MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://text_detection/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n",
      "Saved markdown to ./../../test_output\\WisTMP 7554 COMMENT\n",
      "Total time: 28.57677984237671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Recognizing layout:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Recognizing layout:  50%|█████     | 1/2 [00:07<00:07,  7.49s/it]\n",
      "Recognizing layout: 100%|██████████| 2/2 [00:08<00:00,  3.96s/it]\n",
      "Recognizing layout: 100%|██████████| 2/2 [00:08<00:00,  4.49s/it]\n",
      "\n",
      "Running OCR Error Detection:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Running OCR Error Detection:  50%|█████     | 1/2 [00:00<00:00,  1.97it/s]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00,  2.33it/s]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00,  2.26it/s]\n",
      "\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "\n",
      "Recognizing tables:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Recognizing tables:  33%|███▎      | 1/3 [00:07<00:15,  7.88s/it]\n",
      "Recognizing tables:  67%|██████▋   | 2/3 [00:13<00:06,  6.37s/it]\n",
      "Recognizing tables: 100%|██████████| 3/3 [00:16<00:00,  4.80s/it]\n",
      "Recognizing tables: 100%|██████████| 3/3 [00:16<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "!marker_single \"./../../test_input/WisTMP 7554 COMMENT.pdf\" \\\n",
    "  --output_format markdown \\\n",
    "  --disable_image_extraction \\\n",
    "  --output_dir \"./../../test_output\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn all PDF to MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://text_detection/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n",
      "Converting 1530 pdfs in chunk 1/1 with 1 processes and saving to ./../../Output_M\n",
      "Processing PDFs: 100%|███████████████████| 1530/1530 [3:34:32<00:00,  8.41s/pdf]\n",
      "[W227 03:27:42.251676268 CudaIPCTypes.cpp:96] Producer process tried to deallocate over 1000 memory blocks referred by consumer processes. Deallocation might be significantly slowed down. We assume it will never going to be the case, but if it is, please file but to https://github.com/pytorch/pytorch\n",
      "[W227 03:27:43.749919792 CudaIPCTypes.cpp:16] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n"
     ]
    }
   ],
   "source": [
    "!marker ./../../data \\\n",
    "  --workers 1 \\\n",
    "  --output_format markdown \\\n",
    "  --disable_image_extraction \\\n",
    "  --output_dir \"./../../Output_M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "!python -c \"import torchvision; print(torchvision.__version__)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all unwanted json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Find all .json files in the directory and subdirectories\n",
    "def remove_json_files(directory):\n",
    "    json_files = glob.glob(os.path.join(directory, \"**\", \"*.json\"), recursive=True) # \"**\" is a recursive wildcard, meaning it will search in all subdirectories.\n",
    "\n",
    "    for file in json_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n",
    "\n",
    "target_directory = \"./../../Output_M\"  \n",
    "\n",
    "remove_json_files(target_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
